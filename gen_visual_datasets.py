import os
import torch
from torchvision import datasets, transforms
import numpy as np
from PIL import Image
import warnings
warnings.filterwarnings('ignore')

# ===================== æ ¸å¿ƒé…ç½® =====================
# æ•°æ®é›†æ ¹ç›®å½•ï¼ˆç”Ÿæˆçš„å›¾ç‰‡ä¼šå­˜åœ¨è¿™é‡Œï¼Œå¯ä¿®æ”¹ï¼‰
DATA_ROOT = "./data"
# è§£å†³å›½å†…ä¸‹è½½æ…¢ï¼šé˜¿é‡Œäº‘é•œåƒ
os.environ['TORCH_VISION_DATASETS_MIRROR'] = 'https://mirrors.aliyun.com/pytorch-vision-datasets/'
os.makedirs(DATA_ROOT, exist_ok=True)

# ===================== 1. MNIST è½¬å¯è§†åŒ–å›¾ç‰‡ï¼ˆæ‰‹å†™æ•°å­—ï¼Œå•é€šé“ï¼‰ =====================
def convert_mnist_to_images():
    print("===== ä¸‹è½½å¹¶è½¬æ¢MNISTä¸ºå¯æŸ¥çœ‹çš„å›¾ç‰‡ =====")
    # åŠ è½½MNISTåŸå§‹æ•°æ®é›†ï¼ˆä¸åšå½’ä¸€åŒ–ï¼Œæ–¹ä¾¿ä¿å­˜å›¾ç‰‡ï¼‰
    mnist_transform = transforms.Compose([transforms.ToTensor()])  # ä»…è½¬å¼ é‡ï¼Œä¸å½’ä¸€åŒ–
    train_mnist = datasets.MNIST(DATA_ROOT, train=True, download=True, transform=mnist_transform)
    test_mnist = datasets.MNIST(DATA_ROOT, train=False, download=True, transform=mnist_transform)

    # å®šä¹‰MNISTä¿å­˜è·¯å¾„ï¼ˆtrain/test + æ•°å­—ç±»åˆ«ï¼‰
    mnist_train_root = os.path.join(DATA_ROOT, "MNIST_images/train")
    mnist_test_root = os.path.join(DATA_ROOT, "MNIST_images/test")

    # ä¿å­˜è®­ç»ƒé›†å›¾ç‰‡
    for idx, (img_tensor, label) in enumerate(train_mnist):
        # å¼ é‡è½¬PILå›¾ç‰‡ï¼ˆå•é€šé“ï¼š[1,28,28] â†’ [28,28]ï¼‰
        img_np = img_tensor.squeeze(0).numpy() * 255  # ä»[0,1]è½¬å›[0,255]
        img_pil = Image.fromarray(img_np.astype(np.uint8), mode='L')  # L=ç°åº¦å›¾
        # åˆ›å»ºç±»åˆ«æ–‡ä»¶å¤¹
        label_dir = os.path.join(mnist_train_root, str(label))
        os.makedirs(label_dir, exist_ok=True)
        # ä¿å­˜å›¾ç‰‡ï¼ˆå‘½åï¼šidx.pngï¼‰
        img_path = os.path.join(label_dir, f"{idx}.png")
        img_pil.save(img_path)
        # è¿›åº¦æç¤ºï¼ˆæ¯10000å¼ æ‰“å°ä¸€æ¬¡ï¼‰
        if idx % 10000 == 0 and idx > 0:
            print(f"MNISTè®­ç»ƒé›†å·²ä¿å­˜ {idx} å¼ å›¾ç‰‡")

    # ä¿å­˜æµ‹è¯•é›†å›¾ç‰‡
    for idx, (img_tensor, label) in enumerate(test_mnist):
        img_np = img_tensor.squeeze(0).numpy() * 255
        img_pil = Image.fromarray(img_np.astype(np.uint8), mode='L')
        label_dir = os.path.join(mnist_test_root, str(label))
        os.makedirs(label_dir, exist_ok=True)
        img_path = os.path.join(label_dir, f"{idx}.png")
        img_pil.save(img_path)

    print(f"âœ… MNISTå›¾ç‰‡è½¬æ¢å®Œæˆï¼")
    print(f"   è®­ç»ƒé›†è·¯å¾„ï¼š{mnist_train_root}")
    print(f"   æµ‹è¯•é›†è·¯å¾„ï¼š{mnist_test_root}")

# ===================== 2. CIFAR-10 è½¬å¯è§†åŒ–å›¾ç‰‡ï¼ˆå½©è‰²ï¼ŒæŒ‰ç±»åˆ«å‘½åï¼‰ =====================
def convert_cifar10_to_images():
    print("\n===== ä¸‹è½½å¹¶è½¬æ¢CIFAR-10ä¸ºå¯æŸ¥çœ‹çš„å›¾ç‰‡ =====")
    # CIFAR-10ç±»åˆ«åç§°ï¼ˆ0-9å¯¹åº”ï¼‰
    cifar10_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',
                       'dog', 'frog', 'horse', 'ship', 'truck']
    # åŠ è½½CIFAR-10åŸå§‹æ•°æ®é›†
    cifar_transform = transforms.Compose([transforms.ToTensor()])
    train_cifar10 = datasets.CIFAR10(DATA_ROOT, train=True, download=True, transform=cifar_transform)
    test_cifar10 = datasets.CIFAR10(DATA_ROOT, train=False, download=True, transform=cifar_transform)

    # å®šä¹‰CIFAR-10ä¿å­˜è·¯å¾„
    cifar_train_root = os.path.join(DATA_ROOT, "CIFAR10_images/train")
    cifar_test_root = os.path.join(DATA_ROOT, "CIFAR10_images/test")

    # ä¿å­˜è®­ç»ƒé›†å›¾ç‰‡
    for idx, (img_tensor, label) in enumerate(train_cifar10):
        # å¼ é‡è½¬PILå›¾ç‰‡ï¼ˆå½©è‰²ï¼š[3,32,32] â†’ [32,32,3]ï¼‰
        img_np = img_tensor.permute(1, 2, 0).numpy() * 255  # é€šé“ä»CÃ—HÃ—Wâ†’HÃ—WÃ—C
        img_pil = Image.fromarray(img_np.astype(np.uint8))
        # åˆ›å»ºç±»åˆ«æ–‡ä»¶å¤¹ï¼ˆç”¨ä¸­æ–‡æ˜“ç†è§£çš„åç§°ï¼‰
        label_name = cifar10_classes[label]
        label_dir = os.path.join(cifar_train_root, label_name)
        os.makedirs(label_dir, exist_ok=True)
        # ä¿å­˜å›¾ç‰‡
        img_path = os.path.join(label_dir, f"{idx}.png")
        img_pil.save(img_path)
        if idx % 10000 == 0 and idx > 0:
            print(f"CIFAR-10è®­ç»ƒé›†å·²ä¿å­˜ {idx} å¼ å›¾ç‰‡")

    # ä¿å­˜æµ‹è¯•é›†å›¾ç‰‡
    for idx, (img_tensor, label) in enumerate(test_cifar10):
        img_np = img_tensor.permute(1, 2, 0).numpy() * 255
        img_pil = Image.fromarray(img_np.astype(np.uint8))
        label_name = cifar10_classes[label]
        label_dir = os.path.join(cifar_test_root, label_name)
        os.makedirs(label_dir, exist_ok=True)
        img_path = os.path.join(label_dir, f"{idx}.png")
        img_pil.save(img_path)

    print(f"âœ… CIFAR-10å›¾ç‰‡è½¬æ¢å®Œæˆï¼")
    print(f"   è®­ç»ƒé›†è·¯å¾„ï¼š{cifar_train_root}")
    print(f"   æµ‹è¯•é›†è·¯å¾„ï¼š{cifar_test_root}")

# ===================== 3. éªŒè¯ç”Ÿæˆç»“æœ =====================
def verify_visual_datasets():
    print("\n===== éªŒè¯ç”Ÿæˆçš„å›¾ç‰‡æ•°æ®é›† =====")
    # éªŒè¯MNIST
    mnist_train_0 = os.path.join(DATA_ROOT, "MNIST_images/train/0")
    mnist_test_1 = os.path.join(DATA_ROOT, "MNIST_images/test/1")
    print(f"MNISTè®­ç»ƒé›†0ç±»å›¾ç‰‡æ•°ï¼š{len(os.listdir(mnist_train_0)) if os.path.exists(mnist_train_0) else 'ä¸å­˜åœ¨'}")
    print(f"MNISTæµ‹è¯•é›†1ç±»å›¾ç‰‡æ•°ï¼š{len(os.listdir(mnist_test_1)) if os.path.exists(mnist_test_1) else 'ä¸å­˜åœ¨'}")

    # éªŒè¯CIFAR-10
    cifar_train_airplane = os.path.join(DATA_ROOT, "CIFAR10_images/train/airplane")
    cifar_test_cat = os.path.join(DATA_ROOT, "CIFAR10_images/test/cat")
    print(f"CIFAR-10è®­ç»ƒé›†é£æœºå›¾ç‰‡æ•°ï¼š{len(os.listdir(cifar_train_airplane)) if os.path.exists(cifar_train_airplane) else 'ä¸å­˜åœ¨'}")
    print(f"CIFAR-10æµ‹è¯•é›†çŒ«å›¾ç‰‡æ•°ï¼š{len(os.listdir(cifar_test_cat)) if os.path.exists(cifar_test_cat) else 'ä¸å­˜åœ¨'}")

    print("\nğŸ‰ æ‰€æœ‰å¯æŸ¥çœ‹çš„å›¾ç‰‡æ•°æ®é›†ç”Ÿæˆå®Œæˆï¼")
    print(f"ğŸ“‚ æ€»ç›®å½•ï¼š{os.path.abspath(DATA_ROOT)}")
    print("ğŸ” ç›´æ¥æ‰“å¼€è¯¥ç›®å½•ï¼Œå¯çœ‹åˆ°MNIST_images/CIFAR10_imagesæ–‡ä»¶å¤¹ï¼Œé‡Œé¢train/teståˆ†å¥½ç±»ï¼ŒåŒå‡»å›¾ç‰‡å³å¯æŸ¥çœ‹ï¼")

# ===================== ä¸»å‡½æ•° =====================
if __name__ == "__main__":
    convert_mnist_to_images()
    convert_cifar10_to_images()
    verify_visual_datasets()